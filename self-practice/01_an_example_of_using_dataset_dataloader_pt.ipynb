{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of using Dataset, DataLoader of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create dataset\n",
    "X, y = datasets.make_regression(\n",
    "    n_samples=1000, n_features=10, noise=5, random_state=4)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X_scaled, y_scaled, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "  '''Dataset Class to store the samples and their corresponding labels, \n",
    "  and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "    self.X = torch.from_numpy(X.astype(np.float32))\n",
    "    self.y = torch.from_numpy(y.astype(np.float32))\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return self.len\n",
    "  \n",
    "# Generate the training dataset\n",
    "traindata = Data(X_train, y_train)\n",
    "\n",
    "batch_size = 64\n",
    "# tells the data loader instance how many sub-processes to use for data loading\n",
    "# if the num_worker is zero (default) the GPU has to weight for CPU to load data\n",
    "# Theoretically, greater the num_workers, \n",
    "# more efficiently the CPU load data and less the GPU has to wait\n",
    "num_workers = 2\n",
    "\n",
    "# Load the training data into data loader with the \n",
    "# respective batch_size and num_workers\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, \n",
    "                         shuffle=True, num_workers=num_workers)\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "  '''Linear Regression Model\n",
    "  '''\n",
    "\n",
    "  def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "    '''The network has 4 layers\n",
    "         - input layer\n",
    "         - hidden layer\n",
    "         - hidden layer\n",
    "         - output layer\n",
    "    '''\n",
    "    super(LinearRegression, self).__init__()\n",
    "    self.input_to_hidden = nn.Linear(input_dim, hidden_dim)\n",
    "    self.hidden_layer_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.hidden_layer_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.hidden_to_output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # no activation and no softmax at the end\n",
    "    x = self.input_to_hidden(x)\n",
    "    x = self.hidden_layer_1(x)\n",
    "    x = self.hidden_layer_2(x)\n",
    "    x = self.hidden_to_output(x)\n",
    "    return x\n",
    "  \n",
    "# number of features (len of X cols)\n",
    "input_dim = X_train.shape[1]\n",
    "# number of hidden layers\n",
    "hidden_layers = 50\n",
    "# output dimension is 1 because of linear regression\n",
    "output_dim = 1\n",
    "# initiate the linear regression model\n",
    "model = LinearRegression(input_dim, hidden_layers, output_dim)\n",
    "print(model)\n",
    "\n",
    "# criterion to computes the loss between input and target\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer that will be used to update weights and biases\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# start training\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  for i, (inputs, labels) in enumerate(trainloader):\n",
    "    # inputs, labels = data\n",
    "\n",
    "    # forward propagation\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # set optimizer to zero grad \n",
    "    # to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  # display statistics\n",
    "  if not ((epoch + 1) % (epochs // 10)):\n",
    "    print(f'Epochs:{epoch + 1:5d} | ' \\\n",
    "          f'Batches per epoch: {i + 1:3d} | ' \\\n",
    "          f'Loss: {running_loss / (i + 1):.10f}')\n",
    "    \n",
    "testdata = Data(X_test, y_test)\n",
    "testloader = DataLoader(testdata, batch_size=batch_size, \n",
    "                        shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Validate trained model using the test dataset\n",
    "with torch.no_grad():\n",
    "  loss = 0\n",
    "  for i, (inputs, labels) in enumerate(testloader):\n",
    "    # calculate output by running through the network\n",
    "    predictions = model(inputs)\n",
    "    labels = torch.from_numpy(y_scaler.inverse_transform(labels))\n",
    "    predictions = torch.from_numpy(y_scaler.inverse_transform(predictions))\n",
    "    loss += F.mse_loss(predictions, labels)\n",
    "  print(f'MSE Loss: {loss / (i + 1):.5f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
