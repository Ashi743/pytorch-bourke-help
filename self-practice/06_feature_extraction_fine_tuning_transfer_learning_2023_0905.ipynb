{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libs\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import gdown\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# torch libs\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set seed \n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "# date info\n",
    "now_str = datetime.now().strftime(\"%a, %d %b %Y %H:%M:%S\")\n",
    "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "datetime_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# current dirctory\n",
    "current_dir = os.getcwd()\n",
    "current_dirname = os.path.basename(current_dir)\n",
    "\n",
    "# project directory\n",
    "project_name = f\"06_transfer_learning_feature_extractiion_fine_tuning_{date_str}\"\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = Path('../../data/')\n",
    "if not DATA_DIR.is_dir():\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# log directory\n",
    "LOG_DIR = Path(f'../../logs/{project_name}')\n",
    "if not LOG_DIR.is_dir():\n",
    "    LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_FILE_PATH = LOG_DIR.joinpath(f\"06_transfer_learning_feature_extractiion_fine_tuning__{datetime_str}.log\")\n",
    "\n",
    "# history curves, prediction results - feature extraction\n",
    "HISTORY_CURVES_FEATURE_EXTRACTION_PATH = LOG_DIR.joinpath(f\"history_curves_feature_extraction_{datetime_str}.png\")\n",
    "PREDICTION_RESULTS_FEATURE_EXTRACTION_FILE_PATH = LOG_DIR.joinpath(f\"prediction_results_feature_extraction_{datetime_str}.png\")\n",
    "\n",
    "# history curves, prediction results - fine-tuning\n",
    "HISTORY_CURVES_FINE_TUNING_PATH = LOG_DIR.joinpath(f\"history_curves_fine_tuning_{datetime_str}.png\")\n",
    "PREDICTION_RESULTS_FINE_TUNING_FILE_PATH = LOG_DIR.joinpath(f\"prediction_results_fine_tuning_{datetime_str}.png\")\n",
    "\n",
    "# model directory\n",
    "MODEL_DIR = Path(f'../../models/{project_name}')\n",
    "if not MODEL_DIR.is_dir():\n",
    "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# saved model - feature extraction\n",
    "MODEL_FEATURE_EXTRACTION_STATE_DICT_FILE_PATH = MODEL_DIR.joinpath(f\"feature_extraction_state_dict_{datetime_str}.pt\")\n",
    "MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH = MODEL_DIR.joinpath(f\"feature_extraction_full_model_{datetime_str}.pt\")\n",
    "\n",
    "# saved model - fine-tuning\n",
    "MODEL_FINE_TUNING_STATE_DICT_FILE_PATH = MODEL_DIR.joinpath(f\"fine_tuning_state_dict_{datetime_str}.pt\")\n",
    "MODEL_FINE_TUNING_FULL_MODEL_FILE_PATH = MODEL_DIR.joinpath(f\"fine_tuning_full_model_{datetime_str}.pt\")\n",
    "\n",
    "# tensorboard directory\n",
    "TENSORBOARD_DIR = Path(f'../../tensorboards/{project_name}')\n",
    "if not TENSORBOARD_DIR.is_dir():\n",
    "    TENSORBOARD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tensorboards for feature extraction, fine_tuning\n",
    "TENSORBOARD_FEATURE_EXTRACTION_DIR = MODEL_DIR.joinpath(f\"feature_extraction_{datetime_str}\")\n",
    "TENSORBOARD_FINE_TUNING_DIR = MODEL_DIR.joinpath(f\"fine_tuning_{datetime_str}\")\n",
    "\n",
    "# logging configuration\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     datefmt=\"%a, %d %b %Y %H:%M:%S\",\n",
    "#     format=\"[%(asctime)s.%(msecs)03d] %(levelname)s - %(message)s\",\n",
    "#     handlers=[\n",
    "#         logging.FileHandler(filename=LOG_FILE_PATH, mode=\"w\"),\n",
    "#         logging.StreamHandler()\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# created date\n",
    "print(f\"Created date: Tue, 05 Sep 2023 10:58:54\")\n",
    "\n",
    "# modified date\n",
    "print(f\"Modified date: {now_str}\")\n",
    "\n",
    "# version info\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "# device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# num of gpus\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"GPUs: {num_gpus}\")\n",
    "\n",
    "# cuda version\n",
    "cuda_version = torch.version.cuda \n",
    "print(f\"cuda version: {cuda_version}\")\n",
    "\n",
    "\n",
    "## dataset\n",
    "# urls\n",
    "DATASET_10_PERCENT_URL = \"https://drive.google.com/uc?id=1hPOgpX369z8nSeOK2FaXYQ-hvEsTvqt0\"\n",
    "DATASET_FULL_URL = \"https://drive.google.com/uc?id=1KzCRboc-Ncxh4W7bj0Xnfemrqok2k1Kk\"\n",
    "\n",
    "# dataset zipfile names\n",
    "DATASET_10_PERCENT_ZIPFILE_NAME = \"101_food_classes_10_percent.zip\"\n",
    "DATASET_FULL_ZIPFILE_NAME = \"food101.zip\"\n",
    "\n",
    "# dataset folder names\n",
    "DATASET_10_PERCENT_FOLDER_NAME = \"101_food_classes_10_percent\"\n",
    "DATASET_FULL_FOLDER_NAME = \"food101\"\n",
    "\n",
    "# dataset zipfile paths\n",
    "DATASET_10_PERCENT_ZIPFILE_PATH = DATA_DIR.joinpath(DATASET_10_PERCENT_ZIPFILE_NAME)\n",
    "DATASET_FULL_ZIPFILE_PATH = DATA_DIR.joinpath(DATASET_FULL_ZIPFILE_NAME)\n",
    "\n",
    "# dataset folder paths\n",
    "DATASET_10_PERCENT_FOLDER_PATH = DATA_DIR.joinpath(DATASET_10_PERCENT_FOLDER_NAME)\n",
    "DATASET_FULL_FOLDER_PATH = DATA_DIR.joinpath(DATASET_FULL_FOLDER_NAME)\n",
    "\n",
    "# download 10 percents dataset\n",
    "if not DATASET_10_PERCENT_ZIPFILE_PATH.is_file():\n",
    "    print(f\"The {DATASET_10_PERCENT_ZIPFILE_NAME} is downloading...\")\n",
    "    try:\n",
    "        gdown.download(url=DATASET_10_PERCENT_URL, output=str(DATASET_10_PERCENT_ZIPFILE_PATH))\n",
    "        print(f\"The {DATASET_10_PERCENT_ZIPFILE_NAME} downloaded successfully.\")\n",
    "    except Exception as error:\n",
    "        print(f\"Caught this error: {error}\")\n",
    "else:\n",
    "    print(f\"The {DATASET_10_PERCENT_ZIPFILE_NAME} already exists\")\n",
    "\n",
    "\n",
    "# download full dataset\n",
    "if not DATASET_FULL_ZIPFILE_PATH.is_file():\n",
    "    print(f\"The {DATASET_FULL_ZIPFILE_NAME} is downloading...\")\n",
    "    try:\n",
    "        gdown.download(url=DATASET_FULL_URL, output=str(DATASET_FULL_ZIPFILE_PATH))\n",
    "        print(f\"The {DATASET_FULL_ZIPFILE_NAME} downloaded successfully.\")\n",
    "    except Exception as error:\n",
    "        print(f\"Caught this error: {error}\")\n",
    "else:\n",
    "    print(f\"The {DATASET_FULL_ZIPFILE_NAME} already exists\")\n",
    "\n",
    "\n",
    "# extract 10 percents dataset\n",
    "if not DATASET_10_PERCENT_FOLDER_PATH.is_dir():\n",
    "    print(f\"The {DATASET_10_PERCENT_ZIPFILE_NAME} is extracting...\")\n",
    "    try:\n",
    "        gdown.extractall(path=str(DATASET_10_PERCENT_ZIPFILE_PATH), to=str(DATA_DIR))\n",
    "        print(f\"The {DATASET_10_PERCENT_ZIPFILE_NAME} extracted successfully.\")\n",
    "    except Exception as error:\n",
    "        print(f\"Caught this error: {error}\")\n",
    "else:\n",
    "    print(f\"The {DATASET_10_PERCENT_FOLDER_NAME} already exists\")\n",
    "\n",
    "\n",
    "# extract full dataset\n",
    "if not DATASET_FULL_FOLDER_PATH.is_dir():\n",
    "    print(f\"The {DATASET_FULL_ZIPFILE_NAME} is extracting...\")\n",
    "    try:\n",
    "        gdown.extractall(path=str(DATASET_FULL_ZIPFILE_PATH), to=str(DATA_DIR))\n",
    "        print(f\"The {DATASET_FULL_ZIPFILE_NAME} extracted successfully.\")\n",
    "    except Exception as error:\n",
    "        print(f\"Caught this error: {error}\")\n",
    "else:\n",
    "    print(f\"The {DATASET_FULL_FOLDER_NAME} already exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset Preparing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_data(dataset_dir: Path, ratio: float = 0.1) -> Path:\n",
    "\n",
    "    # original - dataset dir\n",
    "    original_dataset_dir = dataset_dir.joinpath(\"train\")\n",
    "\n",
    "    # val directory\n",
    "    val_dir = dataset_dir.joinpath(\"val\")\n",
    "    if not val_dir.is_dir():\n",
    "        val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # class dirs\n",
    "        class_dirs = [entry.path for entry in os.scandir(original_dataset_dir)]\n",
    "        print(f\"len(class_dirs): {len(class_dirs)}\")\n",
    "\n",
    "        # looping each class directory\n",
    "        for class_dir in class_dirs:\n",
    "        \n",
    "            # all files in the dataset directory\n",
    "            filepaths = glob.glob(os.path.join(class_dir, f\"*jpg\"))\n",
    "\n",
    "            # total files\n",
    "            total_files = len(filepaths)\n",
    "            \n",
    "            # selected files by ratio\n",
    "            selected_files = int(ratio * total_files)\n",
    "            \n",
    "            print(f\"total_files: {total_files}\")\n",
    "            print(f\"selected files: {selected_files}\")\n",
    "            \n",
    "            # randomly sample\n",
    "            selected_filepaths = random.sample(filepaths, k= selected_files)\n",
    "\n",
    "            # looping the selected files\n",
    "            for selected_filepath in selected_filepaths:\n",
    "                \n",
    "                # class name\n",
    "                file_class_name = Path(selected_filepath).parents[0].name\n",
    "                \n",
    "                # var class directory\n",
    "                val_class_dir = val_dir.joinpath(file_class_name)\n",
    "                if not val_class_dir.is_dir():\n",
    "                    val_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # copy files to val directory\n",
    "                print(f\"Moving a file from {selected_filepath} to {val_class_dir} directory\")\n",
    "                shutil.move(src=selected_filepath, dst=val_class_dir)\n",
    "    else:\n",
    "        print(f\"The validation directory {val_dir} already exists. Skipped this process.\")\n",
    "\n",
    "    return val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 percents - train dir\n",
    "train_dir_10_percent = DATASET_10_PERCENT_FOLDER_PATH.joinpath(\"train\")\n",
    "\n",
    "# 10 percents - test dir\n",
    "test_dir_10_percent = DATASET_10_PERCENT_FOLDER_PATH.joinpath(\"test\")\n",
    "\n",
    "# 10 percents - val dir\n",
    "val_dir_10_percent = create_validation_data(dataset_dir= DATASET_10_PERCENT_FOLDER_PATH)\n",
    "\n",
    "# full - train dir\n",
    "train_dir_full = DATASET_FULL_FOLDER_PATH.joinpath(\"train\")\n",
    "\n",
    "# full - test dir\n",
    "test_dir_full = DATASET_FULL_FOLDER_PATH.joinpath(\"test\")\n",
    "\n",
    "# full - val dir\n",
    "val_dir_full = create_validation_data(dataset_dir= DATASET_FULL_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the 10 percents - train dir\n",
    "for filepaths, dirnames, filenames in os.walk(train_dir_10_percent):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the 10 percents - test dir\n",
    "for filepaths, dirnames, filenames in os.walk(test_dir_10_percent):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the 10 percents - val dir\n",
    "for filepaths, dirnames, filenames in os.walk(val_dir_10_percent):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the full - train dir\n",
    "for filepaths, dirnames, filenames in os.walk(train_dir_full):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the full - test dir\n",
    "for filepaths, dirnames, filenames in os.walk(test_dir_full):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the full - val dir\n",
    "for filepaths, dirnames, filenames in os.walk(val_dir_full):\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"There are {len(filenames)} images in {filepaths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset Preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size \n",
    "batch_size = 512\n",
    "\n",
    "# train transform\n",
    "train_transform = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# test transform\n",
    "test_transform = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# validation transform\n",
    "val_transform = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "## 10 percent dataset\n",
    "\n",
    "# train 10 percent dataset\n",
    "train_10_percent_dataset = ImageFolder(root=train_dir_10_percent, transform=train_transform)\n",
    "\n",
    "# test 10 percent dataset\n",
    "test_10_percent_dataset = ImageFolder(root=test_dir_10_percent, transform=test_transform)\n",
    "\n",
    "# val 10 percent dataset\n",
    "val_10_percent_dataset = ImageFolder(root=val_dir_10_percent, transform=val_transform)\n",
    "\n",
    "# train 10 percent dataloader \n",
    "train_10_percent_dataloader = DataLoader(dataset=train_10_percent_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         pin_memory=True)\n",
    "\n",
    "# test 10 percent dataloader \n",
    "test_10_percent_dataloader = DataLoader(dataset=test_10_percent_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True)\n",
    "# val 10 percent dataloader \n",
    "val_10_percent_dataloader = DataLoader(dataset=val_10_percent_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "## full dataset\n",
    "# train full dataset\n",
    "train_full_dataset = ImageFolder(root=train_dir_full, transform=train_transform)\n",
    "\n",
    "# test full dataset\n",
    "test_full_dataset = ImageFolder(root=test_dir_full, transform=test_transform)\n",
    "\n",
    "# val full dataset\n",
    "val_full_dataset = ImageFolder(root=val_dir_full, transform=val_transform)\n",
    "\n",
    "\n",
    "# train full dataloader \n",
    "train_full_dataloader = DataLoader(dataset=train_full_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         pin_memory=True)\n",
    "\n",
    "# test full dataloader \n",
    "test_full_dataloader = DataLoader(dataset=test_full_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True)\n",
    "# val full dataloader \n",
    "val_full_dataloader = DataLoader(dataset=val_full_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names\n",
    "class_names = train_10_percent_dataset.classes\n",
    "print(f\"len(class_names): {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pretrained Models - Transfer Learning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "efficientnet_b0 = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "print(summary(model=efficientnet_b0, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"],\n",
    "        verbose=1))\n",
    "\n",
    "efficientnet_b0.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing all parameters from the pretrained model `efficientnet_b0`\n",
    "for layer_number, layer in enumerate(efficientnet_b0.parameters()):\n",
    "    layer.requires_grad = False\n",
    "\n",
    "print(summary(model=efficientnet_b0, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"],\n",
    "        verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Feature Extraction `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "feature_extraction_efficientnet_b0 = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "# freezing all parameters from the pretrained model `efficientnet_b0`\n",
    "for layer_number, layer in enumerate(feature_extraction_efficientnet_b0.parameters()):\n",
    "    layer.requires_grad = False\n",
    "\n",
    "# adjust the classifier\n",
    "feature_extraction_efficientnet_b0.classifier = torch.nn.Sequential(\n",
    "    # Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release.\n",
    "    # torch.nn.Dropout2d(p=0.5, inplace=True), \n",
    "    torch.nn.Dropout(p=0.5, inplace=True), \n",
    "    torch.nn.Linear(in_features=1280, out_features=len(class_names))\n",
    ")\n",
    "\n",
    "# print out the trainable params\n",
    "for name, param in feature_extraction_efficientnet_b0.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Trainable: {name} = {param.requires_grad}\")\n",
    "\n",
    "\n",
    "feature_extraction_efficientnet_b0 = torch.nn.parallel.DataParallel(\n",
    "    module=feature_extraction_efficientnet_b0, \n",
    "    device_ids=list(range(num_gpus)))\n",
    "\n",
    "# send model to device \n",
    "feature_extraction_efficientnet_b0 = feature_extraction_efficientnet_b0.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.Adam(params=feature_extraction_efficientnet_b0.parameters(), lr=0.001)\n",
    "\n",
    "# epochs \n",
    "feature_extraction_epochs = 15\n",
    "\n",
    "# history curve dict\n",
    "history_curve_feature_extraction_dict = {\n",
    "    \"accuracy\": [],\n",
    "    \"loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "## LOOPING\n",
    "for epoch in tqdm(range(feature_extraction_epochs)):\n",
    "\n",
    "    # start timer\n",
    "    start_timer = timer()\n",
    "\n",
    "    # TRAINING\n",
    "    accumulated_train_loss = 0.0\n",
    "    accumulated_train_accuracy = 0.0\n",
    "    accumulated_train_batches = 0\n",
    "\n",
    "    for inputs, outputs in train_10_percent_dataloader:\n",
    "\n",
    "        # training mode\n",
    "        feature_extraction_efficientnet_b0.train()\n",
    "\n",
    "        # send data to device\n",
    "        inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_logits = feature_extraction_efficientnet_b0(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_logits, outputs)\n",
    "        accumulated_train_loss += loss.data\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = torch.eq(outputs, torch.argmax(torch.softmax(y_logits, dim=1), dim=1)).sum().item()\n",
    "        accumulated_train_accuracy += (acc / len(y_logits))\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # update batches\n",
    "        accumulated_train_batches += 1\n",
    "\n",
    "    # EVALUATION\n",
    "    feature_extraction_efficientnet_b0.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        accumulated_test_loss = 0.0\n",
    "        accumulated_test_accuracy = 0.0\n",
    "        accumulated_test_batches = 0\n",
    "\n",
    "        for inputs, outputs in test_10_percent_dataloader:\n",
    "\n",
    "\n",
    "            # send data to device\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logits = feature_extraction_efficientnet_b0(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_fn(y_logits, outputs)\n",
    "            accumulated_test_loss += loss.data\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = torch.eq(outputs, torch.argmax(torch.softmax(y_logits, dim=1), dim=1)).sum().item()\n",
    "            accumulated_test_accuracy += (acc / len(y_logits))\n",
    "\n",
    "            # update batches\n",
    "            accumulated_test_batches += 1\n",
    "    \n",
    "    # end timer\n",
    "    end_timer = timer()\n",
    "    execution_time = end_timer = start_timer\n",
    "\n",
    "    # train\n",
    "    accuracy = accumulated_train_accuracy / accumulated_train_batches\n",
    "    loss = accumulated_train_loss / accumulated_train_batches\n",
    "\n",
    "    history_curve_feature_extraction_dict[\"accuracy\"].append(round(accuracy, 3))\n",
    "    history_curve_feature_extraction_dict[\"loss\"].append(round(loss.cpu().numpy().item(), 3))\n",
    "\n",
    "    # test\n",
    "    val_accuracy = accumulated_test_accuracy / accumulated_test_batches\n",
    "    val_loss = accumulated_test_loss / accumulated_test_batches\n",
    "\n",
    "    history_curve_feature_extraction_dict[\"val_accuracy\"].append(round(val_accuracy, 3))\n",
    "    history_curve_feature_extraction_dict[\"val_loss\"].append(round(val_loss.cpu().numpy().item(), 3))\n",
    "\n",
    "    # print out\n",
    "    print(f\"Epoch: {epoch + 1} / {feature_extraction_epochs} | \"\n",
    "          f\"Execution time: {execution_time: .2f}s | \" \n",
    "          f\"accuracy: {accuracy: .2f} | \"\n",
    "          f\"loss: {loss: .3f} | \"\n",
    "          f\"val_accuracy: {val_accuracy: .2f} | \"\n",
    "          f\"val_loss: {accuracy: .2f}\"\n",
    "          )\n",
    "\n",
    "# save the full model\n",
    "torch.save(feature_extraction_efficientnet_b0, MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH)\n",
    "if MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH.is_file():\n",
    "    # getsize() returns in bytes \n",
    "    print(f\"Size of the full feature extraction model: {os.path.getsize(MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH)  / (1024 * 1024): .2f} MB\")\n",
    "\n",
    "# save the state_dict\n",
    "torch.save(feature_extraction_efficientnet_b0.state_dict(), MODEL_FEATURE_EXTRACTION_STATE_DICT_FILE_PATH)\n",
    "if MODEL_FEATURE_EXTRACTION_STATE_DICT_FILE_PATH.is_file():\n",
    "    # getsize() returns in bytes \n",
    "     print(f\"Size of the state_dict feature extraction model: {os.path.getsize(MODEL_FEATURE_EXTRACTION_STATE_DICT_FILE_PATH) / (1024 * 1024): .2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_history_curves(history_curve_dict: list, save_path: Path, type_name: str = \"feature extraction\"):\n",
    "\n",
    "    # get current date\n",
    "    now_str = datetime.now().strftime(\"%Y/%m/%d %H:%M%S\")\n",
    "\n",
    "    # plot title\n",
    "    title = f\"Transfer learning - {type_name} - {now_str}\"\n",
    "\n",
    "    # history curves info\n",
    "    accuracy = history_curve_dict[\"accuracy\"]\n",
    "    loss = history_curve_dict[\"loss\"]\n",
    "    val_accuracy = history_curve_dict[\"val_accuracy\"]\n",
    "    val_loss = history_curve_dict[\"val_loss\"]\n",
    "\n",
    "    # list of epochs\n",
    "    epochs = list(range(len(accuracy)))\n",
    "\n",
    "    # create a plot \n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.suptitle(title)\n",
    "    # accuracy of the training set, and testing set\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, accuracy, c=\"r\", label = \"Training dataset\")\n",
    "    plt.plot(epochs, val_accuracy, c=\"g\", label = \"Testing dataset\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    # loss of the training set, and testing set\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, c=\"r\", label = \"Training dataset\")\n",
    "    plt.plot(epochs, val_loss, c=\"g\", label = \"Testing dataset\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"The history curves of the {type_name} is saved in {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HISTORY CURVES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_history_curves(history_curve_dict=history_curve_feature_extraction_dict, save_path=HISTORY_CURVES_FEATURE_EXTRACTION_PATH, type_name=\"feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MODEL LOADING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples from val_dataloader\n",
    "images, labels = next(iter(val_10_percent_dataloader))\n",
    "\n",
    "# convert to numpy\n",
    "label = labels.cpu().numpy()\n",
    "\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a full mode\n",
    "loaded_feature_extraction_full_model = torch.load(MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH)\n",
    "\n",
    "# send the model to device\n",
    "loaded_feature_extraction_full_model.to(device)\n",
    "\n",
    "# eval the loaded model\n",
    "loaded_feature_extraction_full_model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits =  loaded_feature_extraction_full_model(images.to(device))\n",
    "    y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "# display images with their prediction results\n",
    "plt.figure(figsize=(25, 5))\n",
    "for i, image in enumerate(images[:10]):\n",
    "    \n",
    "    # create a subplot\n",
    "    plt.subplot(2, len(images[:10]) // 2, i + 1)\n",
    "\n",
    "    # change the order of dimentions\n",
    "    image = image.permute((2, 1, 0)).numpy() # (3, 224, 224) -> (224, 224, 3)\n",
    "\n",
    "    # unnomalization\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    unnormalized_image = image * std / mean\n",
    "\n",
    "    # clipping\n",
    "    clipped_image = np.clip(unnormalized_image, 0, 1)\n",
    "\n",
    "    # label \n",
    "    label = class_names[labels[i]]\n",
    "\n",
    "    # predicted label\n",
    "    predicted_label = class_names[y_preds[i]]\n",
    "\n",
    "    if label == predicted_label:\n",
    "        title_color = \"g\"\n",
    "    else:\n",
    "        title_color = \"r\"\n",
    "    \n",
    "    # show title\n",
    "    plt.title(label=f\"Predicted: {predicted_label} | Label: {label}\", color=title_color)\n",
    "\n",
    "    # display images\n",
    "    plt.imshow(clipped_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `FINE TUNING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a full mode\n",
    "loaded_feature_extraction_full_model = torch.load(MODEL_FEATURE_EXTRACTION_FULL_MODEL_FILE_PATH)\n",
    "\n",
    "# unfreezing all layers\n",
    "for name, param in loaded_feature_extraction_full_model.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(summary(model=loaded_feature_extraction_full_model, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"],\n",
    "        verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all layers from the features\n",
    "list_features = []\n",
    "for name, param in loaded_feature_extraction_full_model.features.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        list_features.append(name)\n",
    "\n",
    "print(f\"Total layers before freezing: {len(list_features)}\")\n",
    "\n",
    "# freeze all layers except the last 10 layers\n",
    "list_features = list_features[:-10]\n",
    "\n",
    "print(f\"Total layers after freezing: {len(list_features)}\")\n",
    "for name, param in loaded_feature_extraction_full_model.features.named_parameters():\n",
    "    if name in list_features:\n",
    "        param.requires_grad = False\n",
    "\n",
    "print(summary(model=loaded_feature_extraction_full_model, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"],\n",
    "        verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_feature_extraction_full_model = torch.nn.parallel.DataParallel(\n",
    "    module=loaded_feature_extraction_full_model, \n",
    "    device_ids=list(range(num_gpus)))\n",
    "\n",
    "# send model to device \n",
    "fine_tuning_efficientnet_b0 = loaded_feature_extraction_full_model.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.Adam(params=fine_tuning_efficientnet_b0.parameters(), lr=0.001)\n",
    "\n",
    "# epochs \n",
    "epochs = feature_extraction_epochs + 30\n",
    "\n",
    "# history curve dict\n",
    "history_curve_fine_tuning_dict = {\n",
    "    \"accuracy\": [],\n",
    "    \"loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "## LOOPING\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # start timer\n",
    "    start_timer = timer()\n",
    "\n",
    "    # TRAINING\n",
    "    accumulated_train_loss = 0.0\n",
    "    accumulated_train_accuracy = 0.0\n",
    "    accumulated_train_batches = 0\n",
    "\n",
    "    for inputs, outputs in train_10_percent_dataloader:\n",
    "\n",
    "        # training mode\n",
    "        fine_tuning_efficientnet_b0.train()\n",
    "\n",
    "        # send data to device\n",
    "        inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_logits = fine_tuning_efficientnet_b0(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_logits, outputs)\n",
    "        accumulated_train_loss += loss.data\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = torch.eq(outputs, torch.argmax(torch.softmax(y_logits, dim=1), dim=1)).sum().item()\n",
    "        accumulated_train_accuracy += (acc / len(y_logits))\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # update batches\n",
    "        accumulated_train_batches += 1\n",
    "\n",
    "    # EVALUATION\n",
    "    fine_tuning_efficientnet_b0.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        accumulated_test_loss = 0.0\n",
    "        accumulated_test_accuracy = 0.0\n",
    "        accumulated_test_batches = 0\n",
    "\n",
    "        for inputs, outputs in test_10_percent_dataloader:\n",
    "\n",
    "\n",
    "            # send data to device\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logits = fine_tuning_efficientnet_b0(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_fn(y_logits, outputs)\n",
    "            accumulated_test_loss += loss.data\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = torch.eq(outputs, torch.argmax(torch.softmax(y_logits, dim=1), dim=1)).sum().item()\n",
    "            accumulated_test_accuracy += (acc / len(y_logits))\n",
    "\n",
    "            # update batches\n",
    "            accumulated_test_batches += 1\n",
    "    \n",
    "    # end timer\n",
    "    end_timer = timer()\n",
    "    execution_time = end_timer = start_timer\n",
    "\n",
    "    # train\n",
    "    accuracy = accumulated_train_accuracy / accumulated_train_batches\n",
    "    loss = accumulated_train_loss / accumulated_train_batches\n",
    "\n",
    "    history_curve_fine_tuning_dict[\"accuracy\"].append(round(accuracy, 3))\n",
    "    history_curve_fine_tuning_dict[\"loss\"].append(round(loss.cpu().numpy().item(), 3))\n",
    "\n",
    "    # test\n",
    "    val_accuracy = accumulated_test_accuracy / accumulated_test_batches\n",
    "    val_loss = accumulated_test_loss / accumulated_test_batches\n",
    "\n",
    "    history_curve_fine_tuning_dict[\"val_accuracy\"].append(round(val_accuracy, 3))\n",
    "    history_curve_fine_tuning_dict[\"val_loss\"].append(round(val_loss.cpu().numpy().item(), 3))\n",
    "\n",
    "    # print out\n",
    "    print(f\"Epoch: {epoch + 1} / {epochs} | \"\n",
    "          f\"Execution time: {execution_time: .2f}s | \" \n",
    "          f\"accuracy: {accuracy: .2f} | \"\n",
    "          f\"loss: {loss: .3f} | \"\n",
    "          f\"val_accuracy: {val_accuracy: .2f} | \"\n",
    "          f\"val_loss: {accuracy: .2f}\"\n",
    "          )\n",
    "\n",
    "# save the full model\n",
    "torch.save(fine_tuning_efficientnet_b0, MODEL_FINE_TUNING_FULL_MODEL_FILE_PATH)\n",
    "if MODEL_FINE_TUNING_FULL_MODEL_FILE_PATH.is_file():\n",
    "    # getsize() returns in bytes \n",
    "    print(f\"Size of the full fine tuning model: {os.path.getsize(MODEL_FINE_TUNING_FULL_MODEL_FILE_PATH)  / (1024 * 1024): .2f} MB\")\n",
    "\n",
    "# save the state_dict\n",
    "torch.save(fine_tuning_efficientnet_b0.state_dict(), MODEL_FINE_TUNING_STATE_DICT_FILE_PATH)\n",
    "if MODEL_FINE_TUNING_STATE_DICT_FILE_PATH.is_file():\n",
    "    # getsize() returns in bytes \n",
    "     print(f\"Size of the state_dict fine tuning model: {os.path.getsize(MODEL_FINE_TUNING_STATE_DICT_FILE_PATH) / (1024 * 1024): .2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a full mode\n",
    "loaded_fine_tuning_full_model = torch.load(MODEL_FINE_TUNING_FULL_MODEL_FILE_PATH)\n",
    "\n",
    "# send the model to device\n",
    "loaded_fine_tuning_full_model.to(device)\n",
    "\n",
    "# eval the loaded model\n",
    "loaded_fine_tuning_full_model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits =  loaded_fine_tuning_full_model(images.to(device))\n",
    "    y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "# display images with their prediction results\n",
    "plt.figure(figsize=(25, 5))\n",
    "for i, image in enumerate(images[:10]):\n",
    "    \n",
    "    # create a subplot\n",
    "    plt.subplot(2, len(images[:10]) // 2, i + 1)\n",
    "\n",
    "    # change the order of dimentions\n",
    "    image = image.permute((2, 1, 0)).numpy() # (3, 224, 224) -> (224, 224, 3)\n",
    "\n",
    "    # unnomalization\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    unnormalized_image = image * std / mean\n",
    "\n",
    "    # clipping\n",
    "    clipped_image = np.clip(unnormalized_image, 0, 1)\n",
    "\n",
    "    # label \n",
    "    label = class_names[labels[i]]\n",
    "\n",
    "    # predicted label\n",
    "    predicted_label = class_names[y_preds[i]]\n",
    "\n",
    "    if label == predicted_label:\n",
    "        title_color = \"g\"\n",
    "    else:\n",
    "        title_color = \"r\"\n",
    "    \n",
    "    # show title\n",
    "    plt.title(label=f\"Predicted: {predicted_label} | Label: {label}\", color=title_color)\n",
    "\n",
    "    # display images\n",
    "    plt.imshow(clipped_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tadac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
