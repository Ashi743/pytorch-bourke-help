{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu102\n",
      "Device: cuda\n",
      "Created date: 2023:08:07 18:17:12\n",
      "Modified date: 2023:08:07 23:52:02\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# created date\n",
    "print(\"Created date: 2023:08:07 18:17:12\")\n",
    "\n",
    "# modified date\n",
    "now = datetime.now().strftime(\"%Y:%d:%m %H:%M:%S\")\n",
    "print(f\"Modified date: {now}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate `mean` and `standard deviation(std)` from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: 60000\n",
      "mean: 0.2860405743122101 | std: 0.3530242443084717\n"
     ]
    }
   ],
   "source": [
    "# download training set\n",
    "trainset = FashionMNIST(root=\"../../data\", download= True, train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# load all data from training set\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "\n",
    "# train_data\n",
    "data = next(iter(trainloader))\n",
    "\n",
    "# check length\n",
    "print(f\"train_data size: {len(data[0])}\") # data[0]: train_data, data[1]: train_labels\n",
    "\n",
    "# calculate mean, std\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "\n",
    "print(f\"mean: {mean} | std: {std}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Normalize training set, testing set with `mean` and `std`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_transform\n",
    "normalized_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(std=std, mean=mean)])\n",
    "\n",
    "# training set\n",
    "trainset = FashionMNIST(root=\"../../data\", download= True, train=True, transform= normalized_transform)\n",
    "\n",
    "# testing set\n",
    "testset = FashionMNIST(root=\"../../data\", download= True, train=False, transform= normalized_transform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a `FashionMNISTNeuralNetwork` class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTNeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=784, out_features= 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features= 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features= 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features= 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement training with a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTNeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set manual seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# num of epochs\n",
    "epochs = 50\n",
    "\n",
    "# batch size\n",
    "batch_size = 16\n",
    "\n",
    "# dataloader\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# create an instance of the model\n",
    "fashionmnist_model = FashionMNISTNeuralNetwork()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=fashionmnist_model.parameters(), lr=0.001)\n",
    "\n",
    "# tranfer to device\n",
    "fashionmnist_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights \n",
    "for module in fashionmnist_model.modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.kaiming_normal_(module.weight)\n",
    "        nn.init.constant_(module.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 50 | Train loss:  0.46943 | Train accuracy:  0.83 | Test loss:  0.41731 | Test accuracy:  0.84\n",
      "Epoch: 2 / 50 | Train loss:  0.36495 | Train accuracy:  0.86 | Test loss:  0.38994 | Test accuracy:  0.86\n",
      "Epoch: 3 / 50 | Train loss:  0.33088 | Train accuracy:  0.88 | Test loss:  0.36735 | Test accuracy:  0.86\n",
      "Epoch: 4 / 50 | Train loss:  0.30686 | Train accuracy:  0.89 | Test loss:  0.35247 | Test accuracy:  0.87\n",
      "Epoch: 5 / 50 | Train loss:  0.28952 | Train accuracy:  0.89 | Test loss:  0.38665 | Test accuracy:  0.87\n",
      "Epoch: 6 / 50 | Train loss:  0.27533 | Train accuracy:  0.90 | Test loss:  0.37769 | Test accuracy:  0.87\n",
      "Epoch: 7 / 50 | Train loss:  0.26378 | Train accuracy:  0.90 | Test loss:  0.33948 | Test accuracy:  0.88\n",
      "Epoch: 8 / 50 | Train loss:  0.25415 | Train accuracy:  0.90 | Test loss:  0.35115 | Test accuracy:  0.88\n",
      "Epoch: 9 / 50 | Train loss:  0.24289 | Train accuracy:  0.91 | Test loss:  0.34494 | Test accuracy:  0.88\n",
      "Epoch: 10 / 50 | Train loss:  0.23255 | Train accuracy:  0.91 | Test loss:  0.36223 | Test accuracy:  0.88\n",
      "Epoch: 11 / 50 | Train loss:  0.22545 | Train accuracy:  0.91 | Test loss:  0.35423 | Test accuracy:  0.89\n",
      "Epoch: 12 / 50 | Train loss:  0.21995 | Train accuracy:  0.92 | Test loss:  0.37509 | Test accuracy:  0.88\n",
      "Epoch: 13 / 50 | Train loss:  0.21472 | Train accuracy:  0.92 | Test loss:  0.37145 | Test accuracy:  0.89\n",
      "Epoch: 14 / 50 | Train loss:  0.20893 | Train accuracy:  0.92 | Test loss:  0.40046 | Test accuracy:  0.88\n",
      "Epoch: 15 / 50 | Train loss:  0.20487 | Train accuracy:  0.92 | Test loss:  0.37158 | Test accuracy:  0.89\n",
      "Epoch: 16 / 50 | Train loss:  0.19816 | Train accuracy:  0.93 | Test loss:  0.39128 | Test accuracy:  0.89\n",
      "Epoch: 17 / 50 | Train loss:  0.19064 | Train accuracy:  0.93 | Test loss:  0.39047 | Test accuracy:  0.89\n",
      "Epoch: 18 / 50 | Train loss:  0.18804 | Train accuracy:  0.93 | Test loss:  0.40829 | Test accuracy:  0.88\n",
      "Epoch: 19 / 50 | Train loss:  0.18223 | Train accuracy:  0.93 | Test loss:  0.45307 | Test accuracy:  0.88\n",
      "Epoch: 20 / 50 | Train loss:  0.18409 | Train accuracy:  0.93 | Test loss:  0.43644 | Test accuracy:  0.88\n",
      "Epoch: 21 / 50 | Train loss:  0.17733 | Train accuracy:  0.93 | Test loss:  0.46155 | Test accuracy:  0.89\n",
      "Epoch: 22 / 50 | Train loss:  0.17930 | Train accuracy:  0.94 | Test loss:  0.40354 | Test accuracy:  0.89\n",
      "Epoch: 23 / 50 | Train loss:  0.16533 | Train accuracy:  0.94 | Test loss:  0.45441 | Test accuracy:  0.89\n",
      "Epoch: 24 / 50 | Train loss:  0.16955 | Train accuracy:  0.94 | Test loss:  0.41644 | Test accuracy:  0.89\n",
      "Epoch: 25 / 50 | Train loss:  0.16513 | Train accuracy:  0.94 | Test loss:  0.45799 | Test accuracy:  0.89\n",
      "Epoch: 26 / 50 | Train loss:  0.16312 | Train accuracy:  0.94 | Test loss:  0.50055 | Test accuracy:  0.88\n",
      "Epoch: 27 / 50 | Train loss:  0.15715 | Train accuracy:  0.94 | Test loss:  0.44019 | Test accuracy:  0.89\n",
      "Epoch: 28 / 50 | Train loss:  0.15420 | Train accuracy:  0.94 | Test loss:  0.49913 | Test accuracy:  0.89\n",
      "Epoch: 29 / 50 | Train loss:  0.15539 | Train accuracy:  0.94 | Test loss:  0.48426 | Test accuracy:  0.89\n",
      "Epoch: 30 / 50 | Train loss:  0.15386 | Train accuracy:  0.94 | Test loss:  0.49385 | Test accuracy:  0.89\n",
      "Epoch: 31 / 50 | Train loss:  0.14947 | Train accuracy:  0.95 | Test loss:  0.52028 | Test accuracy:  0.88\n",
      "Epoch: 32 / 50 | Train loss:  0.14831 | Train accuracy:  0.95 | Test loss:  0.52831 | Test accuracy:  0.89\n",
      "Epoch: 33 / 50 | Train loss:  0.14404 | Train accuracy:  0.95 | Test loss:  0.55426 | Test accuracy:  0.88\n",
      "Epoch: 34 / 50 | Train loss:  0.14445 | Train accuracy:  0.95 | Test loss:  0.56929 | Test accuracy:  0.89\n",
      "Epoch: 35 / 50 | Train loss:  0.14697 | Train accuracy:  0.95 | Test loss:  0.52192 | Test accuracy:  0.89\n",
      "Epoch: 36 / 50 | Train loss:  0.13821 | Train accuracy:  0.95 | Test loss:  0.50566 | Test accuracy:  0.89\n",
      "Epoch: 37 / 50 | Train loss:  0.14055 | Train accuracy:  0.95 | Test loss:  0.52077 | Test accuracy:  0.89\n",
      "Epoch: 38 / 50 | Train loss:  0.13610 | Train accuracy:  0.95 | Test loss:  0.50841 | Test accuracy:  0.89\n",
      "Epoch: 39 / 50 | Train loss:  0.13423 | Train accuracy:  0.95 | Test loss:  0.61688 | Test accuracy:  0.89\n",
      "Epoch: 40 / 50 | Train loss:  0.13110 | Train accuracy:  0.95 | Test loss:  0.62609 | Test accuracy:  0.89\n",
      "Epoch: 41 / 50 | Train loss:  0.13037 | Train accuracy:  0.95 | Test loss:  0.52245 | Test accuracy:  0.89\n",
      "Epoch: 42 / 50 | Train loss:  0.12591 | Train accuracy:  0.95 | Test loss:  0.58319 | Test accuracy:  0.89\n",
      "Epoch: 43 / 50 | Train loss:  0.12974 | Train accuracy:  0.95 | Test loss:  0.59483 | Test accuracy:  0.89\n",
      "Epoch: 44 / 50 | Train loss:  0.12939 | Train accuracy:  0.95 | Test loss:  0.62996 | Test accuracy:  0.88\n",
      "Epoch: 45 / 50 | Train loss:  0.12494 | Train accuracy:  0.96 | Test loss:  0.61691 | Test accuracy:  0.89\n",
      "Epoch: 46 / 50 | Train loss:  0.13018 | Train accuracy:  0.95 | Test loss:  0.62465 | Test accuracy:  0.89\n",
      "Epoch: 47 / 50 | Train loss:  0.12436 | Train accuracy:  0.96 | Test loss:  0.68153 | Test accuracy:  0.89\n",
      "Epoch: 48 / 50 | Train loss:  0.12866 | Train accuracy:  0.96 | Test loss:  0.76190 | Test accuracy:  0.88\n",
      "Epoch: 49 / 50 | Train loss:  0.12249 | Train accuracy:  0.96 | Test loss:  0.65573 | Test accuracy:  0.89\n",
      "Epoch: 50 / 50 | Train loss:  0.11815 | Train accuracy:  0.96 | Test loss:  0.70154 | Test accuracy:  0.89\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ### TRAINING \n",
    "    accumulated_train_batches = 0\n",
    "    accumulated_train_losses = 0.0\n",
    "    accumulated_train_accuracy = 0.0\n",
    "\n",
    "    for inputs, targets in trainloader:\n",
    "\n",
    "        # copy data to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # train mode\n",
    "        fashionmnist_model.train()\n",
    "\n",
    "        # forward pass\n",
    "        y_logits = fashionmnist_model(inputs).squeeze()\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_logits, targets)\n",
    "\n",
    "        # accumulate losses\n",
    "        accumulated_train_losses += loss\n",
    "\n",
    "        # accumulate batches\n",
    "        accumulated_train_batches += 1\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = torch.eq(targets, torch.argmax(torch.softmax(y_logits.data, dim=1), dim=1)).sum().item()\n",
    "        accumulated_train_accuracy += acc\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward \n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = accumulated_train_losses / accumulated_train_batches\n",
    "    train_acc = accumulated_train_accuracy / (accumulated_train_batches * batch_size)\n",
    "\n",
    "    ### TESTING\n",
    "    fashionmnist_model.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        accumulated_test_batches = 0\n",
    "        accumulated_test_losses = 0.0\n",
    "        accumulated_test_accuracy = 0.0\n",
    "\n",
    "        for inputs, targets in testloader:\n",
    "\n",
    "            # copy data to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logits = fashionmnist_model(inputs).squeeze()\n",
    "\n",
    "            # calculate loss\n",
    "            test_loss = loss_fn(y_logits, targets)\n",
    "\n",
    "            # accumulate losses\n",
    "            accumulated_test_losses += test_loss\n",
    "\n",
    "            # accumulate batches\n",
    "            accumulated_test_batches += 1\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = torch.eq(targets, torch.argmax(torch.softmax(y_logits.data, dim=1), dim=1)).sum().item()\n",
    "            accumulated_test_accuracy += acc\n",
    "\n",
    "    test_loss = accumulated_test_losses / accumulated_test_batches\n",
    "    test_acc = accumulated_test_accuracy / (accumulated_test_batches * batch_size)\n",
    "\n",
    "\n",
    "    print(f\"Epoch: {epoch+1} / {epochs} | Train loss: {train_loss: 0.5f} | Train accuracy: {train_acc: 0.2f} | Test loss: {test_loss: 0.5f} | Test accuracy: {test_acc: 0.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tadac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
